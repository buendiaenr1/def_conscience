# def_conscience
Definir conciencia



## des.py  

El problema en este caso es que se necesita ajustar cada resumen resumen a mano para ver de forma extensa dicho resumen, por lo que se cre√≥ la app en python para arreglar ese problema.
The problem in this case is that each summary needs to be adjusted manually in order to view it in full (shrink to unshrink), so the Python app was created to fix that problem.
Example: https://philpapers.org/s/intentionality%20AND%20ai    

### ...
Mindshaping and AI: Will Mindshaping a Robot Create an Artificial Person?John Dorsch - forthcoming - In Tad Zawidzki, Routledge Handbook of Mindshaping. pp. 406-417.
This chapter examines possible ramifications of mindshaping a social robot. It explores how such an agent might learn to represent psychological states, align its behavior with evolving societal norms, and develop capacities for self-directed mindreading and normative self-knowledge. Integrating perspectives from cultural evolution and naturalized intentionality, this approach suggests that social robots could achieve a level of norm-based self-regulation typically reserved for humans, fulfilling criteria for moral and legal personhood. However, this possibility raises ethical concerns: creating a self-knowing agent (...)
### ...
Mindshaping and AI: Will Mindshaping a Robot Create an Artificial Person?John Dorsch - forthcoming - In Tad Zawidzki, Routledge Handbook of Mindshaping. pp. 406-417.
This chapter examines possible ramifications of mindshaping a social robot. It explores how such an agent might learn to represent psychological states, align its behavior with evolving societal norms, and develop capacities for self-directed mindreading and normative self-knowledge. Integrating perspectives from cultural evolution and naturalized intentionality, this approach suggests that social robots could achieve a level of norm-based self-regulation typically reserved for humans, fulfilling criteria for moral and legal personhood. However, this possibility raises ethical concerns: creating a self-knowing agent would tax care-giving resources as we would need to provide AI welfare, thus undermining our capacity to act responsibly toward humans, non-human animals, and the environment, to whom our moral consideration is already owed and in desperate need. Thus, this chapter concludes by urging caution, warning that attempts to cultivate moral responsibility in artificial agents may have destabilizing consequences for moral practices. (shrink)

## urls.txt
https://philpapers.org/s/phenomenology%20AND%20machine%20learning
https://philpapers.org/s/qualia%20AND%20computational%20models
https://philpapers.org/s/emotion%20AND%20neuroeducation
https://philpapers.org/s/global%20neuronal%20Workspace%20AND%20simulation
https://philpapers.org/s/embodied%20cognition%20AND%20ai%20limitations
https://philpapers.org/s/theory%20of%20Mind%20AND%20machine%20consciousness
https://philpapers.org/s/neuroplasticity%20AND%20emotional%20modulation
https://philpapers.org/s/affective%20computing%20AND%20phenomenological%20gap
https://philpapers.org/s/intentionality%20AND%20ai

